{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab77bf2-74e3-4452-a598-bc643c97c0e9",
   "metadata": {},
   "source": [
    "# Merging Census 2021 and 2011 Data\n",
    "Part of [london-data](https://github.com/jamesdamillington/london-data), by [jamesdamillington](https://github.com/jamesdamillington)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b5664a-db54-424a-a0f8-acdeaa3ae21b",
   "metadata": {},
   "source": [
    "## Overview \n",
    "\n",
    "This notebook contains code to create a dataset of UK census data for London to enable consistent comparison and analysis between 2011 and 2021 (as some LSOA and MSOA boundaries have change; borough boundaries remain unchanged). \n",
    "\n",
    "We utilise the ['exact fit lookup' file](https://hub.arcgis.com/datasets/ons::lsoa-2011-to-lsoa-2021-to-local-authority-district-2022-lookup-for-england-and-wales-version-2/about) between LSOAs. This lookup table has a _'change indicator'_ field that indicates which super output areas have changed between 2011 and 2021 (and how):\n",
    "- **U**: _No Change from 2011 to 2021._ This means that direct comparisons can be made between these 2011 and 2021 LSOA.\n",
    "- **S**: _Split._ This means that the 2011 LSOA has been split into two or more 2021 LSOA. There will be one record for each of the 2021 LSOA that the 2011 LSOA has been split into. This means direct comparisons can be made between estimates for the single 2011 LSOA and the estimates from the aggregated 2021 LSOA.\n",
    "- **M**: _Merged._ 2011 LSOA have been merged with another one or more 2011 LSOA to form a single 2021 LSOA. This means direct comparisons can be made between the aggregated 2011 LSOAs’ estimates and the single 2021 LSOA’s estimates. \n",
    "- **X**: _The relationship between 2011 and 2021 LSOA is irregular and fragmented._ This has occurred where 2011 LSOA have been redesigned because of local authority district boundary changes, or to improve their social homogeneity. These can’t be easily mapped to equivalent 2021 LSOA like the regular splits (S) and merges (M), and therefore like for like comparisons of estimates for 2011 LSOA and 2021 LSOA are not possible. _Luckily there are none of these for London LSOAs!_\n",
    "\n",
    "Merged 2011 LSOAs can accounted for easily: assuming the variable is a count we simply sum the values for the multiple 2011 LSOAs and apply to the new 2021 LSOA. \n",
    "\n",
    "2011 LSOAs that have been split into two or more 2021 LSOas are not so straight-forward and we need to make assumptions about the distribution of people/households across space. If we assume that populations are evenly distributed across space, we can use the areal proportion of the 2011 LSOA that the new (multiple) 2021 LSOAs contributed and scale 2011 data values by those proportions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bbd36a-3197-42be-87ec-c2c7653d8d6c",
   "metadata": {},
   "source": [
    "The first part of the notebook 'Create Dataset' provides code to merge multiple variables from 2011 and 2021 census into a single data file. \n",
    "\n",
    "The second part of the notebook, 'Proof-of-concept', works through the required steps using just a single variable (this was actually written first, before the final code). This second part also creates the `\"Lookup-ExactFit-LSOA11_to_LSOA21_to_LAD22_EW_Version_2-London.csv\"` file used in the first part of the notebook to subset data to London only (from England and Wales).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b97135c-349d-42b6-baa5-86bca9e82656",
   "metadata": {},
   "source": [
    "### Required Libraries\n",
    "The notebook assumes either the `sds2023` or `london-data` virtual environment has been activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f977fb1-2848-4728-a40f-c38da60533f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last tested: 2023-09-25\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "print(f'Last tested: {date.today()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd23fcf-0697-4d28-ac68-a9d080980652",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "\n",
    "When executed the code should read, manipulate, and write a final dataset containing Uk Census data for both 2021 and 2011, with a consistent (2021) data deography. The code reads a metadata file which specifies what variables to include (and the corresponding datafiles for those variables. \n",
    "\n",
    "The general structure of the code is as follows:\n",
    "1. import the required libaries\n",
    "2. define a function to read and manipulate data for each variable\n",
    "3. set data paths and read ancillary data\n",
    "4. read and Manipulate census data\n",
    "5. write data to file\n",
    "\n",
    "The function defined in step 2 and the code in step 4 do the majority of the heavy-lifting. See comments in the code for further details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e090d77-a075-4454-8365-d90cabee5a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:\n",
      "1. import packages\n",
      "2. define function\n",
      "3. read ancillary data\n",
      "4a. loop over variables:\n",
      "TotRes21\n",
      "TotRes11\n",
      "TotHHolds21\n",
      "TotHHolds11\n",
      "FemRes21\n",
      "FemRes11\n",
      "MalRes21\n",
      "MalRes11\n",
      "Asian21\n",
      "Asian11\n",
      "Black21\n",
      "Black11\n",
      "MixedE21\n",
      "MixedE11\n",
      "White21\n",
      "White11\n",
      "OtherE21\n",
      "OtherE11\n",
      "CarsZero21\n",
      "CarsZero11\n",
      "CarsOne21\n",
      "CarsOne11\n",
      "CarsTwo21\n",
      "CarsTwo11\n",
      "CarsThrp21\n",
      "CarsThrp11\n",
      "EconEm21\n",
      "EconEm11\n",
      "EconUn21\n",
      "EconUn11\n",
      "EconSt21\n",
      "EconSt11\n",
      "EconRe21\n",
      "EconRe11\n",
      "EconOt21\n",
      "EconOt11\n",
      "SocAB21\n",
      "SocAB11\n",
      "SocC121\n",
      "SocC111\n",
      "SocC221\n",
      "SocC211\n",
      "SocDE21\n",
      "SocDE11\n",
      "AgeChild21\n",
      "AgeChild11\n",
      "AgeAdult21\n",
      "AgeAdult11\n",
      "AgeSenior21\n",
      "AgeSenior11\n",
      "HealthVG21\n",
      "HealthVG11\n",
      "HealthGood21\n",
      "HealthGood11\n",
      "HealthFair21\n",
      "HealthFair11\n",
      "HealthBad21\n",
      "HealthBad11\n",
      "HealthVB21\n",
      "HealthVB11\n",
      "QualNone21\n",
      "QualNone11\n",
      "QualSch21\n",
      "QualSch11\n",
      "QualUni21\n",
      "QualUni11\n",
      "QualOt21\n",
      "QualOt11\n",
      "4c. MAUP issue\n",
      "5. write data\n"
     ]
    }
   ],
   "source": [
    "#1. import the required libaries\n",
    "print(\"Progress:\")\n",
    "print(\"1. import packages\")\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"2. define function\")\n",
    "#2. define a function to read and manipulate data for each variable\n",
    "def read_cdata(dpath, idf, yr):\n",
    "\n",
    "    #in the two-row df, first row is 2021, second is 2011\n",
    "    i = 0\n",
    "    gc = 'geography code'\n",
    "    if(yr == 2011):\n",
    "        i = 1\n",
    "        gc = 'GeographyCode'\n",
    "    \n",
    "    #print progress\n",
    "    print(idf['Series'].iloc[i])  \n",
    "    \n",
    "    dat = pd.read_csv(dpath / idf['DataFile'].iloc[i])  #get DataFile name and read \n",
    "\n",
    "    #the custom age data for 2021 are in a different format to all other data, so deal with them first\n",
    "    if(idf['Series'].iloc[i] == 'AgeChild21' or idf['Series'].iloc[i] == 'AgeAdult21' or idf['Series'].iloc[i] == 'AgeSenior21'):\n",
    "        \n",
    "        #create lists of the age category codes to filter on below\n",
    "        childCodes = list(range(1, 7))\n",
    "        adultCodes = list(range(7, 18))\n",
    "        seniorCodes = list(range(18,24))\n",
    "        \n",
    "        #filter data for this age category\n",
    "        if(idf['Series'].iloc[i] == 'AgeChild21'):\n",
    "            dat = dat[dat['Age (23 categories) Code'].isin(childCodes)]\n",
    "        \n",
    "        if(idf['Series'].iloc[i] == 'AgeAdult21'):\n",
    "            dat = dat[dat['Age (23 categories) Code'].isin(adultCodes)]\n",
    "        \n",
    "        if(idf['Series'].iloc[i] == 'AgeSenior21'):\n",
    "            dat = dat[dat['Age (23 categories) Code'].isin(seniorCodes)]\n",
    "        \n",
    "        #sum age groups by LSOA (into one of our three age categories) \n",
    "        dat = dat.groupby('Lower layer Super Output Areas Code')['Observation'].sum().reset_index()\n",
    "        \n",
    "        #rename columns for merging into final data table later\n",
    "        dat = dat.rename(columns={'Lower layer Super Output Areas Code':'LSOA21CD'})\n",
    "        dat = dat.rename(columns={'Observation':idf['Series'].iloc[i]})\n",
    "        \n",
    "        return(dat)    \n",
    "    \n",
    "    #now handle all non-Age21 data\n",
    "    else:\n",
    "        #if there are multiple variables, split them on comma\n",
    "        vids = idf['Variable_ids'].iloc[i].split(\",\")   #this breaks for 2021 Asian and Black variables because of comma (work-around below)\n",
    "        vids = [x.strip(' ') for x in vids]    #remove spaces at the beginning and at the end of the string\n",
    "\n",
    "        #annoyingly there are commas in column names for some variables, work-around here: \n",
    "        if(idf['Series'].iloc[i] == 'Asian21'):\n",
    "            vids = [\"Ethnic group: Asian, Asian British or Asian Welsh\"]\n",
    "        if(idf['Series'].iloc[i] == 'Black21'):\n",
    "            vids = [\"Ethnic group: Black, Black British, Black Welsh, Caribbean or African\"]\n",
    "        if(idf['Series'].iloc[i] == 'SocC121'):\n",
    "            vids = [\"C1 Supervisory, clerical and junior managerial/administrative/professional occupations\"]\n",
    "\n",
    "\n",
    "        vids.insert(0, gc)  #add LSOA code column to the list of columns we want to retain\n",
    "        #ts11 = ts11[[c for c in ts11.columns if c in vids]]  #safer than ts[vids] if column missing\n",
    "        dat = dat[vids]  #drop unwanted variables (columns) from the data\n",
    "\n",
    "        dat = dat.set_index(gc)  #set index here \n",
    " \n",
    "        #2011 data may have multiple columns, these need to be summed \n",
    "        if dat.shape[i] > 1:\n",
    "            dat[idf['Series'].iloc[i]] = dat.sum(axis=1)  #sum (renaming column)\n",
    "            dat = dat.loc[:, [idf['Series'].iloc[i]]]   #return as a df, not Series\n",
    "        #when only a single column, no need to sum (just rename column)    \n",
    "        else:\n",
    "            dat = dat.rename(columns={vids[i]:idf['Series'].iloc[i]})\n",
    "\n",
    "        #reset the index (back to a regular column) as we need this for merging later\n",
    "        dat = dat.reset_index()  \n",
    "        if(yr == 2011):\n",
    "            dat = dat.rename(columns={'GeographyCode':'LSOA11CD'})\n",
    "        else:\n",
    "            dat = dat.rename(columns={'geography code':'LSOA21CD'})\n",
    "\n",
    "        return(dat)\n",
    "\n",
    "print(\"3. read ancillary data\")\n",
    "#3. Set data paths and read ancillary data\n",
    "#set input and output paths\n",
    "census_igpath = Path(\"../data/inputs/geographies/census/\")\n",
    "census_icpath = Path(\"../data/inputs/census/\")\n",
    "census_opath = Path(\"../data/census/\")\n",
    "census_gpath = Path(\"../data/geographies/census/\")\n",
    "\n",
    "#geometry, area data come from shapefiles \n",
    "boundaries = gpd.read_file(census_gpath / \"london-2021-lsoa.shp\").set_index('LSOA21NM')\n",
    "geometry = gpd.read_file(census_gpath / \"london-2021-lsoa-gen20.shp\")\n",
    "\n",
    "#read meta file\n",
    "metad = pd.read_csv(census_icpath / \"UKCensus-2021-2011-London-metadata.csv\",\n",
    "                    usecols=['Series', 'Variable_ids', 'Year', 'DataFile'])\n",
    "finalcolumns = metad['Series']  #save for later to re-order output variables (metad will be changed before that)\n",
    "\n",
    "#read the file detailing 2011-2021 LSOA matches\n",
    "dat_efit = pd.read_csv(census_igpath / \"Lookup-ExactFit-LSOA11_to_LSOA21_to_LAD22_EW_Version_2-London.csv\")\n",
    "\n",
    "    \n",
    "#4. Read and Manipulate census data\n",
    "print(\"4a. loop over variables:\")\n",
    "#4a. 'double loop' over the metadata file (two rows at a time - 2011 and 2021 for each variable) applying the function defined above\n",
    "#this manipulates the raw census data (e.g. aggregating sub-variables) and does not address 2011vs2021 MAUP issue \n",
    "metad.dropna(inplace=True)  #if there are any rows in the metadata with missing values, ignore these variables\n",
    "metad = metad[~metad.Series.str.endswith('_21c')]   #drop rows for 21c as we will calculate values for these later\n",
    "metad = metad.reset_index(drop=True)  #needed for 'double loop' below\n",
    "\n",
    "#loop\n",
    "for i, g in metad.groupby(metad.index // 2):\n",
    "    \n",
    "    #use function above to read the data in a format we can then use to merge\n",
    "    dat21 = read_cdata(census_icpath, g, 2021)\n",
    "    dat11 = read_cdata(census_icpath, g, 2011)\n",
    "    \n",
    "    #merge original data for 2011 and 2021\n",
    "    dat_efit = pd.merge(dat_efit, dat11, how='left', on='LSOA11CD')  #need to merge here on LSOA11CD\n",
    "    dat_efit = pd.merge(dat_efit, dat21, how='left', on='LSOA21CD')  #merge here on LSOA21CD\n",
    "\n",
    "#4b. Calculate LSOA areas and merge with 2011 and 2021 data\n",
    "boundaries['LSOA21KM2'] = round(boundaries['geometry'].area / 10**6, 5)  #calculate area of each LSOA\n",
    "areas = boundaries[['LSOA21CD', 'LSOA21KM2', 'MSOA21CD', 'MSOA21NM']]  #drop unwanted columns\n",
    "geometry = geometry[['LSOA21CD', 'geometry']]  #drop unwanted columns\n",
    "\n",
    "#merge in area data    \n",
    "dat_efit = pd.merge(dat_efit, areas, how='left', on='LSOA21CD')\n",
    "\n",
    "#4c. Address 2011vs2021 MAUP issue by calculating 2011 values for 2021 LSOA areas\n",
    "print(\"4c. MAUP issue\")\n",
    "#calculate proportion of 2021 LSOA that 2011 LSOA composes\n",
    "dat_efit['LSOAP21'] = round(dat_efit['LSOA21KM2'] / dat_efit.groupby('LSOA11CD')['LSOA21KM2'].transform('sum'),4)\n",
    "\n",
    "#add change indicator column\n",
    "dat_efit.loc[dat_efit['CHGIND'] == 'M', 'LSOAP21'] = 2\n",
    "\n",
    "#now calculate 21c variable values and add to dataframe                      \n",
    "for i, g in metad.groupby(metad.index // 2):\n",
    "\n",
    "    newnm = g['Series'].iloc[1] + \"_21c\"  #name for column to be created\n",
    "    dat_efit[newnm] = round(dat_efit[g['Series'].iloc[1]] * dat_efit['LSOAP21']) #calc proportional area value for 2021 from 2011 \n",
    "    #overwrite values for 2021 LSOAs produced by merging 2011 LSOAs \n",
    "    dat_efit.loc[dat_efit['CHGIND']=='M',newnm] = dat_efit[dat_efit['CHGIND']=='M'].groupby('LSOA21CD')[g['Series'].iloc[1]].transform('sum')\n",
    "\n",
    "#merge in gemetry data (using 2021 gemetry)    \n",
    "dat_efit = pd.merge(dat_efit, geometry, how='left', on='LSOA21CD')\n",
    "\n",
    "print(\"5. write data\")\n",
    "#5. Write data to file\n",
    "#reorder columns for output  (with help from https://stackoverflow.com/a/53299403)\n",
    "#metad = pd.read_csv(census_icpath / \"london-census21-metadata.csv\",usecols=['Series'])\n",
    "existing = [i for i in finalcolumns if i in dat_efit.columns]\n",
    "dat_efit = dat_efit[existing]\n",
    "\n",
    "#print to file\n",
    "dat_efit.to_csv(census_opath / \"UKCensus-2021-2011-London-data.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6a146-6c1f-4cd7-9d28-8b33c91a42d5",
   "metadata": {},
   "source": [
    "## Proof of Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb5223-6b0f-4fcc-944f-4bee3a304249",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "1. Read Data\n",
    "    - Read exact fit lookup\n",
    "        - subset to London Boroughs\n",
    "    - Read 2011 data (e.g. KS101EWDATA06.CSV from [here](https://www.nomisweb.co.uk/census/2011/bulk/r2_2))\n",
    "    - Read 2021 data (e.g. census2021-ts001-lsoa.csv from [here](https://www.nomisweb.co.uk/census/2021/bulk))\n",
    "    - Read 2021 geometries (london-2021-lsoa.shp created [here](https://github.com/jamesdamillington/london-data/blob/main/code/london-census2021-geography.ipynb))\n",
    "    - calculate polygon area\n",
    "2. Merge Data\n",
    "    - Merge 2011 data to bestfit on LSOA11CD \n",
    "    - Merge 2021 data to bestfit on LSOA21CD\n",
    "    - Merge 2021 areas on LSOA21CD\n",
    "3. Calculate Areal Proportions\n",
    "    - Create '2021 area prop' column:\n",
    "        - Where CHGIND is U, set value 1\n",
    "        - Where CHGIND is M, set value 2\n",
    "        - Where CHGIND is S: calculate proportion from sum of areas for LSOAs with identical LSOA11CD \n",
    "4. Set Values\n",
    "    - Create 'merged 2011' column\n",
    "        - Where CHGIND is U, use original 2011 data value \n",
    "        - Where CHGIND is M, use sum of 2011 LSOAs with the LSOA21CD for M\n",
    "        - Where CHGIND is S, multiply original 2011 data value by '2021 area prop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6b00974-8bd6-4b62-9046-31fb39fe9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da5ccc-6654-46d3-9d28-72649f9e75c3",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "Read exact fit lookup spreadsheet then subset to London Boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423d4a0c-f0dd-487a-a33b-9ec0cab65361",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_igpath = Path(\"../data/inputs/geographies/census/\")\n",
    "efit = pd.read_csv(census_igpath / \"Lookup-ExactFit-LSOA11_to_LSOA21_to_LAD22_EW_Version_2.csv\",\n",
    "                      usecols = list(range(7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023d6776-3cb9-4c30-8fda-e0dbdad1dec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35796 entries, 0 to 35795\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   LSOA11CD  35796 non-null  object\n",
      " 1   LSOA11NM  35796 non-null  object\n",
      " 2   LSOA21CD  35796 non-null  object\n",
      " 3   LSOA21NM  35796 non-null  object\n",
      " 4   CHGIND    35796 non-null  object\n",
      " 5   LAD22CD   35796 non-null  object\n",
      " 6   LAD22NM   35796 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "efit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9751bda-c79d-4731-b43a-165089bce7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['City of London', 'Barking and Dagenham', 'Bexley', 'Barnet',\n",
       "       'Brent', 'Bromley', 'Croydon', 'Camden', 'Ealing', 'Enfield',\n",
       "       'Greenwich', 'Hackney', 'Haringey', 'Hammersmith and Fulham',\n",
       "       'Hillingdon', 'Harrow', 'Havering', 'Islington', 'Hounslow',\n",
       "       'Kensington and Chelsea', 'Kingston upon Thames', 'Lambeth',\n",
       "       'Lewisham', 'Merton', 'Redbridge', 'Newham', 'Sutton', 'Southwark',\n",
       "       'Richmond upon Thames', 'Tower Hamlets', 'Waltham Forest',\n",
       "       'Wandsworth', 'Bury', 'Bolton', 'Westminster', 'Manchester',\n",
       "       'Oldham', 'Rochdale', 'Salford', 'Stockport', 'Trafford', 'Wigan',\n",
       "       'Tameside', 'Knowsley', 'Liverpool', 'Sefton', 'Wirral',\n",
       "       'St. Helens', 'Doncaster', 'Barnsley', 'Rotherham', 'Sheffield',\n",
       "       'Gateshead', 'Newcastle upon Tyne', 'North Tyneside', 'Sunderland',\n",
       "       'South Tyneside', 'Birmingham', 'Coventry', 'Dudley', 'Sandwell',\n",
       "       'Solihull', 'Walsall', 'Wolverhampton', 'Bradford', 'Calderdale',\n",
       "       'Leeds', 'Kirklees', 'Wakefield', 'Hartlepool', 'Middlesbrough',\n",
       "       'Redcar and Cleveland', 'Stockton-on-Tees', 'Warrington', 'Halton',\n",
       "       'Blackburn with Darwen', 'Darlington',\n",
       "       'Kingston upon Hull, City of', 'East Riding of Yorkshire',\n",
       "       'Blackpool', 'North East Lincolnshire', 'North Lincolnshire',\n",
       "       'York', 'Derby', 'Leicester', 'Nottingham', 'Rutland',\n",
       "       'Herefordshire, County of', 'Stoke-on-Trent', 'Telford and Wrekin',\n",
       "       'Bristol, City of', 'Bath and North East Somerset',\n",
       "       'North Somerset', 'South Gloucestershire', 'Plymouth',\n",
       "       'Bournemouth, Christchurch and Poole', 'Torbay', 'Swindon',\n",
       "       'Luton', 'Peterborough', 'Southend-on-Sea', 'Thurrock', 'Medway',\n",
       "       'West Berkshire', 'Bracknell Forest', 'Reading', 'Milton Keynes',\n",
       "       'Slough', 'Windsor and Maidenhead', 'Wokingham',\n",
       "       'Brighton and Hove', 'Portsmouth', 'Southampton', 'Isle of Wight',\n",
       "       'Central Bedfordshire', 'Buckinghamshire', 'Bedford', 'Cambridge',\n",
       "       'Fenland', 'East Cambridgeshire', 'Huntingdonshire',\n",
       "       'Cheshire East', 'Cheshire West and Chester',\n",
       "       'South Cambridgeshire', 'Cornwall', 'Allerdale', 'Copeland',\n",
       "       'Barrow-in-Furness', 'South Lakeland', 'Carlisle', 'Eden',\n",
       "       'Isles of Scilly', 'Amber Valley', 'Bolsover', 'Chesterfield',\n",
       "       'Erewash', 'High Peak', 'North East Derbyshire',\n",
       "       'Derbyshire Dales', 'East Devon', 'South Derbyshire',\n",
       "       'North Devon', 'Exeter', 'South Hams', 'Mid Devon', 'Teignbridge',\n",
       "       'West Devon', 'Dorset', 'County Durham', 'Torridge', 'Hastings',\n",
       "       'Eastbourne', 'Lewes', 'Wealden', 'Rother', 'Brentwood',\n",
       "       'Braintree', 'Castle Point', 'Basildon', 'Epping Forest',\n",
       "       'Chelmsford', 'Colchester', 'Harlow', 'Maldon', 'Cotswold',\n",
       "       'Rochford', 'Forest of Dean', 'Cheltenham', 'Tendring',\n",
       "       'Gloucester', 'Uttlesford', 'Stroud', 'East Hampshire',\n",
       "       'Eastleigh', 'Tewkesbury', 'Fareham', 'Basingstoke and Deane',\n",
       "       'Hart', 'New Forest', 'Gosport', 'Rushmoor', 'Havant',\n",
       "       'Test Valley', 'Dacorum', 'East Hertfordshire', 'Hertsmere',\n",
       "       'Winchester', 'Broxbourne', 'North Hertfordshire', 'Three Rivers',\n",
       "       'Stevenage', 'St Albans', 'Welwyn Hatfield', 'Ashford', 'Watford',\n",
       "       'Maidstone', 'Gravesham', 'Sevenoaks', 'Dover', 'Canterbury',\n",
       "       'Dartford', 'Folkestone and Hythe', 'Swale', 'Burnley', 'Thanet',\n",
       "       'Tonbridge and Malling', 'Tunbridge Wells', 'Chorley', 'Lancaster',\n",
       "       'Pendle', 'Hyndburn', 'Fylde', 'Preston', 'Wyre',\n",
       "       'West Lancashire', 'Ribble Valley', 'South Ribble', 'Rossendale',\n",
       "       'Blaby', 'Charnwood', 'Melton', 'Hinckley and Bosworth',\n",
       "       'North West Leicestershire', 'Boston', 'East Lindsey',\n",
       "       'Harborough', 'Oadby and Wigston', 'South Kesteven',\n",
       "       'South Holland', 'Lincoln', 'Breckland', 'North Kesteven',\n",
       "       'Broadland', 'West Lindsey', 'Great Yarmouth',\n",
       "       \"King's Lynn and West Norfolk\", 'Norwich', 'South Norfolk',\n",
       "       'North Norfolk', 'North Northamptonshire', 'West Northamptonshire',\n",
       "       'Northumberland', 'Richmondshire', 'Ryedale', 'Scarborough',\n",
       "       'Craven', 'Harrogate', 'Hambleton', 'Bassetlaw', 'Ashfield',\n",
       "       'Broxtowe', 'Selby', 'Mansfield', 'Gedling', 'Cherwell',\n",
       "       'Rushcliffe', 'South Oxfordshire', 'Newark and Sherwood', 'Oxford',\n",
       "       'Shropshire', 'Vale of White Horse', 'Mendip', 'West Oxfordshire',\n",
       "       'Sedgemoor', 'Somerset West and Taunton', 'Cannock Chase',\n",
       "       'East Staffordshire', 'South Somerset', 'Lichfield', 'Babergh',\n",
       "       'Stafford', 'South Staffordshire', 'Newcastle-under-Lyme',\n",
       "       'Tamworth', 'Staffordshire Moorlands', 'West Suffolk',\n",
       "       'East Suffolk', 'Ipswich', 'Mid Suffolk', 'Elmbridge', 'Runnymede',\n",
       "       'Guildford', 'Spelthorne', 'Reigate and Banstead',\n",
       "       'Epsom and Ewell', 'Mole Valley', 'Surrey Heath', 'Woking',\n",
       "       'North Warwickshire', 'Tandridge', 'Rugby', 'Waverley',\n",
       "       'Nuneaton and Bedworth', 'Crawley', 'Stratford-on-Avon', 'Arun',\n",
       "       'Chichester', 'Warwick', 'Adur', 'Wiltshire', 'Horsham',\n",
       "       'Worthing', 'Mid Sussex', 'Wychavon', 'Wyre Forest', 'Worcester',\n",
       "       'Bromsgrove', 'Redditch', 'Malvern Hills', 'Gwynedd',\n",
       "       'Isle of Anglesey', 'Conwy', 'Denbighshire', 'Flintshire',\n",
       "       'Ceredigion', 'Powys', 'Wrexham', 'Pembrokeshire', 'Swansea',\n",
       "       'Carmarthenshire', 'Neath Port Talbot', 'Bridgend',\n",
       "       'Rhondda Cynon Taf', 'Merthyr Tydfil', 'Vale of Glamorgan',\n",
       "       'Caerphilly', 'Monmouthshire', 'Cardiff', 'Newport',\n",
       "       'Blaenau Gwent', 'Torfaen'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lads = pd.unique(efit.LAD22NM)\n",
    "lads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e87a33e-a593-47c3-af1e-e8d62b14ca55",
   "metadata": {},
   "source": [
    "From this we can see London boroughs _are_ listed first (except for Westminster - Bury and Bolton will need to be dropped), so we can get list of borough names relatively easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9bbdb28-1f14-47bc-95e4-9fd31668a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['City of London', 'Barking and Dagenham', 'Bexley', 'Barnet', 'Brent', 'Bromley', 'Croydon', 'Camden', 'Ealing', 'Enfield', 'Greenwich', 'Hackney', 'Haringey', 'Hammersmith and Fulham', 'Hillingdon', 'Harrow', 'Havering', 'Islington', 'Hounslow', 'Kensington and Chelsea', 'Kingston upon Thames', 'Lambeth', 'Lewisham', 'Merton', 'Redbridge', 'Newham', 'Sutton', 'Southwark', 'Richmond upon Thames', 'Tower Hamlets', 'Waltham Forest', 'Wandsworth', 'Westminster']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "lads = list(lads)\n",
    "london_lads = lads[:lads.index('Westminster')+1]\n",
    "london_lads.remove(\"Bury\")\n",
    "london_lads.remove(\"Bolton\")\n",
    "print(london_lads)\n",
    "print(len(london_lads))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f779b1e-4c13-4361-8c82-e2beedce3642",
   "metadata": {},
   "source": [
    "Now subset using this list of 33 boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48dba610-fd59-4f6e-93a0-62e05eb51799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>LSOA21CD</th>\n",
       "      <th>LSOA21NM</th>\n",
       "      <th>CHGIND</th>\n",
       "      <th>LAD22CD</th>\n",
       "      <th>LAD22NM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>E01000001</td>\n",
       "      <td>City of London 001A</td>\n",
       "      <td>U</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E01000002</td>\n",
       "      <td>City of London 001B</td>\n",
       "      <td>E01000002</td>\n",
       "      <td>City of London 001B</td>\n",
       "      <td>U</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E01000003</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>E01000003</td>\n",
       "      <td>City of London 001C</td>\n",
       "      <td>U</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E01000005</td>\n",
       "      <td>City of London 001E</td>\n",
       "      <td>E01000005</td>\n",
       "      <td>City of London 001E</td>\n",
       "      <td>U</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>City of London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E01000006</td>\n",
       "      <td>Barking and Dagenham 016A</td>\n",
       "      <td>E01000006</td>\n",
       "      <td>Barking and Dagenham 016A</td>\n",
       "      <td>U</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>Barking and Dagenham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LSOA11CD                   LSOA11NM   LSOA21CD                   LSOA21NM  \\\n",
       "0  E01000001        City of London 001A  E01000001        City of London 001A   \n",
       "1  E01000002        City of London 001B  E01000002        City of London 001B   \n",
       "2  E01000003        City of London 001C  E01000003        City of London 001C   \n",
       "3  E01000005        City of London 001E  E01000005        City of London 001E   \n",
       "4  E01000006  Barking and Dagenham 016A  E01000006  Barking and Dagenham 016A   \n",
       "\n",
       "  CHGIND    LAD22CD               LAD22NM  \n",
       "0      U  E09000001        City of London  \n",
       "1      U  E09000001        City of London  \n",
       "2      U  E09000001        City of London  \n",
       "3      U  E09000001        City of London  \n",
       "4      U  E09000002  Barking and Dagenham  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efit = efit[efit['LSOA21NM'].str.contains(\"|\".join(london_lads))]   #from https://stackoverflow.com/a/71399966\n",
    "efit = efit.copy(deep=False)\n",
    "efit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c9dcd23-9453-43ee-be4c-9d574e0994f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['City of London', 'Barking and Dagenham', 'Bexley', 'Barnet',\n",
       "       'Brent', 'Bromley', 'Croydon', 'Camden', 'Ealing', 'Enfield',\n",
       "       'Greenwich', 'Hackney', 'Haringey', 'Hammersmith and Fulham',\n",
       "       'Hillingdon', 'Harrow', 'Havering', 'Islington', 'Hounslow',\n",
       "       'Kensington and Chelsea', 'Kingston upon Thames', 'Lambeth',\n",
       "       'Lewisham', 'Merton', 'Redbridge', 'Newham', 'Sutton', 'Southwark',\n",
       "       'Richmond upon Thames', 'Tower Hamlets', 'Waltham Forest',\n",
       "       'Wandsworth', 'Westminster', 'Brentwood'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(efit.LAD22NM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea74b67-7b73-4a42-ae70-67efac2dfd4a",
   "metadata": {},
   "source": [
    "We end up including Brentwood (not a London borough) so need to remove this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6ff050d-8124-41b8-9b47-9ea62d03e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "efit = efit[~efit['LSOA21NM'].str.contains('Brentwood')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "add83539-e08f-4151-b6a8-298b7ad128b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['City of London', 'Barking and Dagenham', 'Bexley', 'Barnet',\n",
       "       'Brent', 'Bromley', 'Croydon', 'Camden', 'Ealing', 'Enfield',\n",
       "       'Greenwich', 'Hackney', 'Haringey', 'Hammersmith and Fulham',\n",
       "       'Hillingdon', 'Harrow', 'Havering', 'Islington', 'Hounslow',\n",
       "       'Kensington and Chelsea', 'Kingston upon Thames', 'Lambeth',\n",
       "       'Lewisham', 'Merton', 'Redbridge', 'Newham', 'Sutton', 'Southwark',\n",
       "       'Richmond upon Thames', 'Tower Hamlets', 'Waltham Forest',\n",
       "       'Wandsworth', 'Westminster'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(efit.LAD22NM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5773cbec-3524-4cdd-8bfc-43f6346859bd",
   "metadata": {},
   "source": [
    "This list of unique boroughs in our bestfit table now looks right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2731c6d1-e56e-45e2-8e8c-3cf6f68578b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "efit.to_csv(census_igpath / \"Lookup-ExactFit-LSOA11_to_LSOA21_to_LAD22_EW_Version_2-London.csv\", \n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23035c6f-dfc5-493b-abfb-4423e91b145e",
   "metadata": {},
   "source": [
    "Next, read 2011 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8e27c88-d311-471b-beb6-2423ff1a2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_icpath = Path(\"../data/inputs/census/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecb2c3e7-555f-429c-bdb5-f50c445dbe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts11 = pd.read_csv(census_icpath / \"KS101EWDATA06.CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5846ae75-88d5-4557-846e-6fc8eb17cf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeographyCode</th>\n",
       "      <th>KS101EW0001</th>\n",
       "      <th>KS101EW0002</th>\n",
       "      <th>KS101EW0003</th>\n",
       "      <th>KS101EW0004</th>\n",
       "      <th>KS101EW0005</th>\n",
       "      <th>KS101EW0006</th>\n",
       "      <th>KS101EW0007</th>\n",
       "      <th>KS101EW0008</th>\n",
       "      <th>KS101EW0009</th>\n",
       "      <th>KS101EW0010</th>\n",
       "      <th>KS101EW0011</th>\n",
       "      <th>KS101EW0012</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E01000001</td>\n",
       "      <td>1465</td>\n",
       "      <td>767</td>\n",
       "      <td>698</td>\n",
       "      <td>1465</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>12.98</td>\n",
       "      <td>112.865948</td>\n",
       "      <td>52.354949</td>\n",
       "      <td>47.645051</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E01000002</td>\n",
       "      <td>1436</td>\n",
       "      <td>767</td>\n",
       "      <td>669</td>\n",
       "      <td>1436</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>22.84</td>\n",
       "      <td>62.872154</td>\n",
       "      <td>53.412256</td>\n",
       "      <td>46.587744</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E01000003</td>\n",
       "      <td>1346</td>\n",
       "      <td>714</td>\n",
       "      <td>632</td>\n",
       "      <td>1250</td>\n",
       "      <td>96</td>\n",
       "      <td>12</td>\n",
       "      <td>5.91</td>\n",
       "      <td>227.749577</td>\n",
       "      <td>53.046062</td>\n",
       "      <td>46.953938</td>\n",
       "      <td>92.867756</td>\n",
       "      <td>7.132244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E01000005</td>\n",
       "      <td>985</td>\n",
       "      <td>528</td>\n",
       "      <td>457</td>\n",
       "      <td>985</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18.96</td>\n",
       "      <td>51.951477</td>\n",
       "      <td>53.604061</td>\n",
       "      <td>46.395939</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E01000006</td>\n",
       "      <td>1703</td>\n",
       "      <td>866</td>\n",
       "      <td>837</td>\n",
       "      <td>1699</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>14.66</td>\n",
       "      <td>116.166439</td>\n",
       "      <td>50.851439</td>\n",
       "      <td>49.148561</td>\n",
       "      <td>99.765120</td>\n",
       "      <td>0.234880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  GeographyCode  KS101EW0001  KS101EW0002  KS101EW0003  KS101EW0004  \\\n",
       "0     E01000001         1465          767          698         1465   \n",
       "1     E01000002         1436          767          669         1436   \n",
       "2     E01000003         1346          714          632         1250   \n",
       "3     E01000005          985          528          457          985   \n",
       "4     E01000006         1703          866          837         1699   \n",
       "\n",
       "   KS101EW0005  KS101EW0006  KS101EW0007  KS101EW0008  KS101EW0009  \\\n",
       "0            0           21        12.98   112.865948    52.354949   \n",
       "1            0           22        22.84    62.872154    53.412256   \n",
       "2           96           12         5.91   227.749577    53.046062   \n",
       "3            0            5        18.96    51.951477    53.604061   \n",
       "4            4           16        14.66   116.166439    50.851439   \n",
       "\n",
       "   KS101EW0010  KS101EW0011  KS101EW0012  \n",
       "0    47.645051   100.000000     0.000000  \n",
       "1    46.587744   100.000000     0.000000  \n",
       "2    46.953938    92.867756     7.132244  \n",
       "3    46.395939   100.000000     0.000000  \n",
       "4    49.148561    99.765120     0.234880  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc3d8313-6c9b-44f6-83ae-c0bfe3f503e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts11 = ts11[['GeographyCode', 'KS101EW0001']]\n",
    "ts11 = ts11.set_axis(['LSOA11CD', 'TotalRes11'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bbbb5b8-b104-444c-8e23-3c458bb37cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>TotalRes11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E01000001</td>\n",
       "      <td>1465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E01000002</td>\n",
       "      <td>1436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E01000003</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E01000005</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E01000006</td>\n",
       "      <td>1703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LSOA11CD  TotalRes11\n",
       "0  E01000001        1465\n",
       "1  E01000002        1436\n",
       "2  E01000003        1346\n",
       "3  E01000005         985\n",
       "4  E01000006        1703"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts11.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e1a57f-4fb5-41e7-abb6-d5da3f44de0e",
   "metadata": {},
   "source": [
    "Read 2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "363c5c2b-0727-4fe5-88f7-2c6fb0e8cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts21 = pd.read_csv(census_icpath / \"census2021-ts001-lsoa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc30cf19-eff3-4925-b421-3b93c28205a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>geography</th>\n",
       "      <th>geography code</th>\n",
       "      <th>Residence type: Total; measures: Value</th>\n",
       "      <th>Residence type: Lives in a household; measures: Value</th>\n",
       "      <th>Residence type: Lives in a communal establishment; measures: Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>Hartlepool 001A</td>\n",
       "      <td>E01011954</td>\n",
       "      <td>2284</td>\n",
       "      <td>2284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>Hartlepool 001B</td>\n",
       "      <td>E01011969</td>\n",
       "      <td>1344</td>\n",
       "      <td>1344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>Hartlepool 001C</td>\n",
       "      <td>E01011970</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>Hartlepool 001D</td>\n",
       "      <td>E01011971</td>\n",
       "      <td>1323</td>\n",
       "      <td>1323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>Hartlepool 001F</td>\n",
       "      <td>E01033465</td>\n",
       "      <td>1955</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date        geography geography code  \\\n",
       "0  2021  Hartlepool 001A      E01011954   \n",
       "1  2021  Hartlepool 001B      E01011969   \n",
       "2  2021  Hartlepool 001C      E01011970   \n",
       "3  2021  Hartlepool 001D      E01011971   \n",
       "4  2021  Hartlepool 001F      E01033465   \n",
       "\n",
       "   Residence type: Total; measures: Value  \\\n",
       "0                                    2284   \n",
       "1                                    1344   \n",
       "2                                    1070   \n",
       "3                                    1323   \n",
       "4                                    1955   \n",
       "\n",
       "   Residence type: Lives in a household; measures: Value  \\\n",
       "0                                               2284       \n",
       "1                                               1344       \n",
       "2                                               1070       \n",
       "3                                               1323       \n",
       "4                                               1955       \n",
       "\n",
       "   Residence type: Lives in a communal establishment; measures: Value  \n",
       "0                                                  0                   \n",
       "1                                                  0                   \n",
       "2                                                  0                   \n",
       "3                                                  0                   \n",
       "4                                                  0                   "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts21.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1853c67-f879-4860-8d40-eca127ed642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts21 = ts21[['geography code', 'Residence type: Total; measures: Value']]\n",
    "ts21 = ts21.set_axis(['LSOA21CD', 'TotalRes21'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28486130-dceb-42b0-8adf-c19bd161745a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA21CD</th>\n",
       "      <th>TotalRes21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E01011954</td>\n",
       "      <td>2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E01011969</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E01011970</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E01011971</td>\n",
       "      <td>1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E01033465</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LSOA21CD  TotalRes21\n",
       "0  E01011954        2284\n",
       "1  E01011969        1344\n",
       "2  E01011970        1070\n",
       "3  E01011971        1323\n",
       "4  E01033465        1955"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts21.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40676401-9e4d-49e7-baaa-f71f3b5d7319",
   "metadata": {},
   "source": [
    "Read 2021 geometries then calculate polygon area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df57fa83-8686-43d0-a273-6b70d7397fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_gpath = Path(\"../data/geographies/census/\")\n",
    "boundaries = gpd.read_file(census_gpath / \"london-2021-lsoa.shp\").set_index('LSOA21NM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fd05aac-b525-42c7-98bc-9e9a111eb4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:27700\n"
     ]
    }
   ],
   "source": [
    "print(boundaries.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44130a03-fdea-4600-a730-9cc271214cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries['sqkm21'] = round(boundaries['geometry'].area / 10**6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff4467e6-4c24-46e7-9b9c-45eb4b8f69df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Index: 4994 entries, City of London 001A to Westminster 024G\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   LSOA21CD  4994 non-null   object  \n",
      " 1   MSOA21CD  4994 non-null   object  \n",
      " 2   MSOA21NM  4994 non-null   object  \n",
      " 3   LAD22CD   4994 non-null   object  \n",
      " 4   LAD22NM   4994 non-null   object  \n",
      " 5   geometry  4994 non-null   geometry\n",
      " 6   sqkm21    4994 non-null   float64 \n",
      "dtypes: float64(1), geometry(1), object(5)\n",
      "memory usage: 441.2+ KB\n"
     ]
    }
   ],
   "source": [
    "boundaries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef5bd5c2-7d81-4a46-bcbc-0654c6d24a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = boundaries[['LSOA21CD', 'sqkm21']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62a84c2-a51a-4580-a44e-46eb5dede159",
   "metadata": {},
   "source": [
    "Note that we have dropped the geometry column here. The full resolution (highest precision) geometry data produces a large (~90MB) file so we drop here and will merge simplified geometry (_london-2021-lsoa-gen20.csv_ from `london-census2021-geography.ipynb`) later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a95306-8b3b-47c6-8d07-11ac5d20e34b",
   "metadata": {},
   "source": [
    "### Merge Data\n",
    "- Merge 2011 data to bestfit on LSOA11CD \n",
    "- Merge 2021 data to bestfit on LSOA21CD\n",
    "- Merge 2021 areas on LSOA21CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53a2f06a-4371-4ac1-8e52-786e48a19525",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_efit = pd.merge(efit, ts11, how='left', on='LSOA11CD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c088b247-86a6-4ceb-b903-d3dcfb8ac3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_efit = pd.merge(merge_efit, ts21, how='left', on='LSOA21CD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b34c6fbd-d372-482c-a254-20eebaada2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_efit = pd.merge(merge_efit, areas, how='left', on='LSOA21CD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd0c3490-40cb-47a8-b068-51ff6cdae37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5016 entries, 0 to 5015\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   LSOA11CD    5016 non-null   object \n",
      " 1   LSOA11NM    5016 non-null   object \n",
      " 2   LSOA21CD    5016 non-null   object \n",
      " 3   LSOA21NM    5016 non-null   object \n",
      " 4   CHGIND      5016 non-null   object \n",
      " 5   LAD22CD     5016 non-null   object \n",
      " 6   LAD22NM     5016 non-null   object \n",
      " 7   TotalRes11  5016 non-null   int64  \n",
      " 8   TotalRes21  5016 non-null   int64  \n",
      " 9   sqkm21      5016 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 392.0+ KB\n"
     ]
    }
   ],
   "source": [
    "merge_efit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5763ad0-e96a-407a-a022-4ecf3cd8b91f",
   "metadata": {},
   "source": [
    "### Calculate Proportions\n",
    "- Create '2021 area prop' column:\n",
    "    - Where CHGIND is U, set value 1\n",
    "    - Where CHGIND is M, set value 2\n",
    "    - Where CHGIND is S: calculate proportion from sum of areas for LSOAs with identical LSOA11CD "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c6ad14-4091-4c9b-a5d8-e5d01242bd80",
   "metadata": {},
   "source": [
    "For U and S, groupby 2011 LSOA code and calculate the proportion (this will be 1 for unsplit LSOAs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a60b200-d1d0-4ec7-8cf8-81a0882e7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_efit['prop21'] = round(merge_efit['sqkm21'] / merge_efit.groupby('LSOA11CD')['sqkm21'].transform('sum'),4)\n",
    "#from https://stackoverflow.com/a/57359372"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5db9c2f3-2d3c-4b75-b49d-fb36af0d943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_efit.loc[merge_efit['CHGIND'] == 'M', 'prop21'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2aaa8-7f11-40b7-b3c0-ef91ddefe30e",
   "metadata": {},
   "source": [
    "### Set Values\n",
    "- Create 'merged 2011' column\n",
    "    - Where CHGIND is U, use original 2011 data value \n",
    "    - Where CHGIND is M, use sum of 2011 LSOAs with the LSOA21CD for M\n",
    "    - Where CHGIND is S, multiply original 2011 data value by '2021 area prop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3dc9b37a-07fa-4a08-9ace-d685137fc355",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_efit['TotalRes11_21c'] = round(merge_efit['TotalRes11'] * merge_efit['prop21'])\n",
    "merge_efit['TotalRes11_21c'] = merge_efit['TotalRes11_21c'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0430ce9-0962-4671-96c2-f0d2d8698d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_14676\\1808171169.py:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[2709 2709 3159 3159 3131 3131 2583 2583 3088 3088 2116 2116 3400 3400\n",
      " 4267 4267 3042 3042 3252 3252 3026 3420 3420 2410 2640 2969 2410 2969\n",
      " 2267 2267 3123 3123 2451 2451 2699 2699 2457 2457 3026 2562 2562 2559\n",
      " 2559 2640]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  merge_efit.loc[merge_efit['CHGIND']=='M','TotalRes11_21c'] = merge_efit[merge_efit['CHGIND']=='M'].groupby('LSOA21CD')['TotalRes11'].transform('sum')\n"
     ]
    }
   ],
   "source": [
    "merge_efit.loc[merge_efit['CHGIND']=='M','TotalRes11_21c'] = merge_efit[merge_efit['CHGIND']=='M'].groupby('LSOA21CD')['TotalRes11'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf6e3e8e-ff41-4d1a-b73c-ee361dcb46bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSOA11CD</th>\n",
       "      <th>LSOA11NM</th>\n",
       "      <th>LSOA21CD</th>\n",
       "      <th>LSOA21NM</th>\n",
       "      <th>CHGIND</th>\n",
       "      <th>LAD22CD</th>\n",
       "      <th>LAD22NM</th>\n",
       "      <th>TotalRes11</th>\n",
       "      <th>TotalRes21</th>\n",
       "      <th>sqkm21</th>\n",
       "      <th>prop21</th>\n",
       "      <th>TotalRes11_21c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>E01003109</td>\n",
       "      <td>Lambeth 003E</td>\n",
       "      <td>E01033863</td>\n",
       "      <td>Lambeth 003G</td>\n",
       "      <td>S</td>\n",
       "      <td>E09000022</td>\n",
       "      <td>Lambeth</td>\n",
       "      <td>2255</td>\n",
       "      <td>1325</td>\n",
       "      <td>0.10111</td>\n",
       "      <td>0.3758</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>E01033207</td>\n",
       "      <td>Lambeth 004F</td>\n",
       "      <td>E01033864</td>\n",
       "      <td>Lambeth 004H</td>\n",
       "      <td>S</td>\n",
       "      <td>E09000022</td>\n",
       "      <td>Lambeth</td>\n",
       "      <td>1708</td>\n",
       "      <td>1032</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>E01033207</td>\n",
       "      <td>Lambeth 004F</td>\n",
       "      <td>E01033865</td>\n",
       "      <td>Lambeth 004I</td>\n",
       "      <td>S</td>\n",
       "      <td>E09000022</td>\n",
       "      <td>Lambeth</td>\n",
       "      <td>1708</td>\n",
       "      <td>1520</td>\n",
       "      <td>0.13870</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>E01033207</td>\n",
       "      <td>Lambeth 004F</td>\n",
       "      <td>E01033866</td>\n",
       "      <td>Lambeth 004J</td>\n",
       "      <td>S</td>\n",
       "      <td>E09000022</td>\n",
       "      <td>Lambeth</td>\n",
       "      <td>1708</td>\n",
       "      <td>1120</td>\n",
       "      <td>0.04116</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>E01003927</td>\n",
       "      <td>Southwark 002A</td>\n",
       "      <td>E01033867</td>\n",
       "      <td>Southwark 002F</td>\n",
       "      <td>S</td>\n",
       "      <td>E09000028</td>\n",
       "      <td>Southwark</td>\n",
       "      <td>2377</td>\n",
       "      <td>1547</td>\n",
       "      <td>0.16428</td>\n",
       "      <td>0.5815</td>\n",
       "      <td>1382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LSOA11CD        LSOA11NM   LSOA21CD        LSOA21NM CHGIND    LAD22CD  \\\n",
       "4606  E01003109    Lambeth 003E  E01033863    Lambeth 003G      S  E09000022   \n",
       "4607  E01033207    Lambeth 004F  E01033864    Lambeth 004H      S  E09000022   \n",
       "4608  E01033207    Lambeth 004F  E01033865    Lambeth 004I      S  E09000022   \n",
       "4609  E01033207    Lambeth 004F  E01033866    Lambeth 004J      S  E09000022   \n",
       "4610  E01003927  Southwark 002A  E01033867  Southwark 002F      S  E09000028   \n",
       "\n",
       "        LAD22NM  TotalRes11  TotalRes21   sqkm21  prop21  TotalRes11_21c  \n",
       "4606    Lambeth        2255        1325  0.10111  0.3758             847  \n",
       "4607    Lambeth        1708        1032  0.06158  0.2551             436  \n",
       "4608    Lambeth        1708        1520  0.13870  0.5745             981  \n",
       "4609    Lambeth        1708        1120  0.04116  0.1705             291  \n",
       "4610  Southwark        2377        1547  0.16428  0.5815            1382  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_efit[merge_efit['CHGIND']=='S'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c496de43-9863-48f9-b543-f87e8022649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with help from https://stackoverflow.com/a/68453949\n",
    "cols = ['sqkm21','prop21','TotalRes21','TotalRes11','TotalRes11_21c']\n",
    "merge_efit = merge_efit[[c for c in merge_efit.columns if c not in cols]+ cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f266b5c3-db04-414b-b5fd-3a2221905991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5016 entries, 0 to 5015\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   LSOA11CD        5016 non-null   object \n",
      " 1   LSOA11NM        5016 non-null   object \n",
      " 2   LSOA21CD        5016 non-null   object \n",
      " 3   LSOA21NM        5016 non-null   object \n",
      " 4   CHGIND          5016 non-null   object \n",
      " 5   LAD22CD         5016 non-null   object \n",
      " 6   LAD22NM         5016 non-null   object \n",
      " 7   sqkm21          5016 non-null   float64\n",
      " 8   prop21          5016 non-null   float64\n",
      " 9   TotalRes21      5016 non-null   int64  \n",
      " 10  TotalRes11      5016 non-null   int64  \n",
      " 11  TotalRes11_21c  5016 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(7)\n",
      "memory usage: 470.4+ KB\n"
     ]
    }
   ],
   "source": [
    "merge_efit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1393781a-0685-411b-a0e2-de04fdaa065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_opath = Path(\"../data/census/\")\n",
    "merge_efit.to_csv(census_opath / \"merge_efit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a9fc1f-3eff-45f4-b137-56070294cbeb",
   "metadata": {},
   "source": [
    "MIT License. Copyright (c) 2023 James Millington"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
